{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# Object Detection Demo\n",
    "Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wy72mWwAWKMK"
   },
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v7m_NY_aWKMK"
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5FNuiRPWKMN"
   },
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bm0_uNRnWKMN"
   },
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_sEBLpVWKMQ"
   },
   "source": [
    "## Variables\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_FROZEN_GRAPH` to point to a new .pb file.  \n",
    "\n",
    "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VyPz_t8WWKMQ"
   },
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "#MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "#MODEL_NAME = 'faster_rcnn_resnet101_kitti_2018_01_28'\n",
    "#MODEL_NAME = 'mask_rcnn_inception_v2_coco_2018_01_28'\n",
    "MODEL_NAME = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ai8pLZZWKMS"
   },
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KILYnwR5WKMS"
   },
   "outputs": [],
   "source": [
    "#opener = urllib.request.URLopener()\n",
    "#opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFsoUHvbWKMZ"
   },
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jG-zn5ykWKMd"
   },
   "outputs": [],
   "source": [
    "# For the sake of simplicity we will use only 2 images:\n",
    "# image1.jpg\n",
    "# image2.jpg\n",
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 4) ]\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixation_frames(TRIAL):\n",
    "    fixations_path = os.path.join(str(TRIAL), 'fixations.csv')\n",
    "    df = pd.read_csv(fixations_path)\n",
    "    num_rows = df.shape[0]\n",
    "    \n",
    "    frame_list = []\n",
    "    for i in range(num_rows):\n",
    "        fixation_start = df['start_frame_index'][i]\n",
    "        fixation_end = df['end_frame_index'][i]\n",
    "        frame_list.append((fixation_start + fixation_end) // 2)\n",
    "    \n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bumper_fixations, windshield_fixations, display_fixations = 0, 0, 0\n",
    "car_fixations = 0\n",
    "fixation_df_indices = {'car': [], 'display': [], 'windshield': [], 'bumper': []}\n",
    "output_data = []\n",
    "\n",
    "def init_fixation_counts():\n",
    "    global bumper_fixations, windshield_fixations, display_fixations, car_fixations, output_data\n",
    "    \n",
    "    bumper_fixations, windshield_fixations, display_fixations = 0, 0, 0\n",
    "    car_fixations = 0\n",
    "    fixation_df_indices = {'car': [], 'display': [], 'windshield': [], 'bumper': []}\n",
    "    output_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "92BHxzcNWKMf"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph, x_fix, y_fix, fix_index, display_type, df):\n",
    "  global bumper_fixations, windshield_fixations, display_fixations, car_fixations, fixation_df_indices, output_data\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      im_height, im_width, im_depth = image.shape\n",
    "      \n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "        \n",
    "        #  if (category_index.get(i)['id'] in [1, 3])\n",
    "      \n",
    "      car_indices = [i for i in range(output_dict['num_detections']) if (output_dict['detection_classes'][i] == 3 and output_dict['detection_scores'][i] > 0.65)]\n",
    "      people_indices = [i for i in range(output_dict['num_detections']) if (output_dict['detection_classes'][i] == 1 and output_dict['detection_scores'][i] > 0.7)]\n",
    "      #print([(category_index.get(i)['id'], category_index.get(i)['name']) for i in output_dict['detection_classes']])\n",
    "      \n",
    "      print('car bounding boxes:')\n",
    "      for i in car_indices:\n",
    "        bb = output_dict['detection_boxes'][i]\n",
    "        ymin, xmin, ymax, xmax = bb[0], bb[1], bb[2], bb[3]\n",
    "        (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "        print(\"Bounding boxes coords:\")\n",
    "        print(left, right, top, bottom)\n",
    "        print(\"Scores: \")\n",
    "        print(output_dict['detection_scores'][i])\n",
    "        #print(output_dict['detection_classes'])\n",
    "        print()\n",
    "        \n",
    "        image_area = im_width * im_height * 1.0\n",
    "        fixation = Point(x_fix, y_fix)\n",
    "        car_bb = Polygon([(left, top - (0.15 * (bottom - top))), \n",
    "                          (right, top - (0.15 * (bottom - top))), \n",
    "                          (right, bottom), (left, bottom)])\n",
    "        \n",
    "        car_area = car_bb.area\n",
    "        closeby = False\n",
    "        \n",
    "        if float(car_area) / float(image_area) >= 0.25: # we care about slant of different fixation regions. car is close.\n",
    "            closeby = True\n",
    "            \n",
    "        coord_1 = (left, top - (0.15 * (bottom - top)))\n",
    "        coord_3 = (left, top + (0.1 * (bottom - top)))\n",
    "        coord_5 = (left, top + (0.25 * (bottom - top)))\n",
    "        coord_7 = (left, bottom)\n",
    "        \n",
    "        if not closeby:\n",
    "            coord_1 = (left, top - (0.35 * (bottom - top)))\n",
    "            coord_2 = (right, top - (0.35 * (bottom - top)))\n",
    "            coord_4 = (right, top + (0.1 * (bottom - top)))\n",
    "            coord_6 = (right, top + (0.25 * (bottom - top)))\n",
    "            coord_8 = (right, bottom)\n",
    "            \n",
    "        else: # shift the right coords up more\n",
    "            coord_2 = (right * 0.75, top - (0.175 * (bottom - top)))\n",
    "            coord_4 = (right * 0.825, top + (0.05 * (bottom - top)))\n",
    "            coord_6 = (right, top + (0.2 * (bottom - top)))\n",
    "            coord_8 = (right, bottom)\n",
    "            \n",
    "        display_bb = Polygon([coord_1, coord_2, coord_4, coord_3])\n",
    "        if 'manual' in str(display_type):\n",
    "            display_bb = Polygon([(-1,-1), (-1,-1), (-1,-1), (-1,-1)])\n",
    "        \n",
    "        windshield_bb = Polygon([coord_3, coord_4, coord_6, coord_5])\n",
    "        bumper_bb = Polygon([coord_5, coord_6, coord_8, coord_7])\n",
    "        \n",
    "        # updated car polygon after analyzing ratio & placement on screen\n",
    "        car_bb = Polygon([coord_1, coord_2, coord_4, coord_6, \n",
    "                          coord_8, coord_7, coord_5, coord_3])\n",
    "        \n",
    "        print('Account for slant: ' + str(closeby))\n",
    "        print('Fixation in car? ' + str(car_bb.contains(fixation)))\n",
    "        print('Display: ' + str(display_bb.contains(fixation)))\n",
    "        print('Windshield: ' + str(windshield_bb.contains(fixation)))\n",
    "        print('Bumper: ' + str(bumper_bb.contains(fixation)))\n",
    "        \n",
    "        output_row = df.iloc[[fix_index]].values.tolist()[0]\n",
    "        \n",
    "        if car_bb.contains(fixation):\n",
    "            car_fixations += 1\n",
    "            fixation_df_indices['car'].append(fix_index)\n",
    "            \n",
    "        if display_bb.contains(fixation):\n",
    "            display_fixations += 1\n",
    "            fixation_df_indices['display'].append(fix_index)\n",
    "            output_row.append('interface')\n",
    "            \n",
    "        elif windshield_bb.contains(fixation):\n",
    "            windshield_fixations += 1\n",
    "            fixation_df_indices['windshield'].append(fix_index)\n",
    "            output_row.append('windshield')\n",
    "            \n",
    "        elif bumper_bb.contains(fixation):\n",
    "            bumper_fixations += 1\n",
    "            fixation_df_indices['bumper'].append(fix_index)\n",
    "            output_row.append('bumper')\n",
    "            \n",
    "        else:\n",
    "            output_row.append('other fixation')\n",
    "            \n",
    "        output_data.append(output_row)\n",
    "      \n",
    "      print()\n",
    "      print('people bounding boxes:')\n",
    "      for i in people_indices:\n",
    "        bb = output_dict['detection_boxes'][i]\n",
    "        ymin, xmin, ymax, xmax = bb[0], bb[1], bb[2], bb[3]\n",
    "        (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "        print(\"Bounding boxes coords:\")\n",
    "        print(left, right, top, bottom)\n",
    "        print(\"Scores: \")\n",
    "        print(output_dict['detection_scores'][i])\n",
    "        #print(output_dict['detection_classes'])\n",
    "        print()\n",
    "  print('-----------')\n",
    "        \n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndate, trial_num, display_type, intersection = TRIAL.split(\\'_\\')\\noutput_data = []\\n\\nif ANALYZE_VIDEO: # we modify TEST_IMAGE_PATHS to be a set of video frames\\n    TEST_IMAGE_PATHS = []\\n    print(\\'analyzing video...\\')\\n    vidObj = cv2.VideoCapture(os.path.join(str(TRIAL), VIDEO_PATH))\\n    count = 1\\n    success = 1\\n    fixations = get_fixation_frames(TRIAL) \\n    \\n    while success:\\n        success, image = vidObj.read() \\n  \\n        # Saves the frames with frame-count \\n        if count in fixations:\\n            cv2.imwrite(os.path.join(str(TRIAL), \\'frame{}.jpg\\'.format(count)), image)\\n            TEST_IMAGE_PATHS.append(os.path.join(str(TRIAL), \\'frame{}.jpg\\'.format(count)))\\n  \\n        count += 1\\nprint(\"Number of frames for this video: {}\".format(len(TEST_IMAGE_PATHS)))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "date, trial_num, display_type, intersection = TRIAL.split('_')\n",
    "output_data = []\n",
    "\n",
    "if ANALYZE_VIDEO: # we modify TEST_IMAGE_PATHS to be a set of video frames\n",
    "    TEST_IMAGE_PATHS = []\n",
    "    print('analyzing video...')\n",
    "    vidObj = cv2.VideoCapture(os.path.join(str(TRIAL), VIDEO_PATH))\n",
    "    count = 1\n",
    "    success = 1\n",
    "    fixations = get_fixation_frames(TRIAL) \n",
    "    \n",
    "    while success:\n",
    "        success, image = vidObj.read() \n",
    "  \n",
    "        # Saves the frames with frame-count \n",
    "        if count in fixations:\n",
    "            cv2.imwrite(os.path.join(str(TRIAL), 'frame{}.jpg'.format(count)), image)\n",
    "            TEST_IMAGE_PATHS.append(os.path.join(str(TRIAL), 'frame{}.jpg'.format(count)))\n",
    "  \n",
    "        count += 1\n",
    "print(\"Number of frames for this video: {}\".format(len(TEST_IMAGE_PATHS)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(TRIAL, f1, f2):\n",
    "    VIDEO_PATH = 'worldwithoutgaze.mp4'\n",
    "    ANALYZE_VIDEO = True\n",
    "    date, trial_num, display_type, intersection = TRIAL.split('_')\n",
    "    global output_data\n",
    "    output_data = []\n",
    "\n",
    "    if ANALYZE_VIDEO: # we modify TEST_IMAGE_PATHS to be a set of video frames\n",
    "        TEST_IMAGE_PATHS = []\n",
    "        print('analyzing video...')\n",
    "        \n",
    "        if os.path.isfile(os.path.join(str(TRIAL), VIDEO_PATH)):\n",
    "            vidObj = cv2.VideoCapture(os.path.join(str(TRIAL), VIDEO_PATH))\n",
    "            \n",
    "        else:\n",
    "            vidObj = cv2.VideoCapture(os.path.join(str(TRIAL), 'world.mp4'))\n",
    "            \n",
    "        count = 1\n",
    "        success = 1\n",
    "        fixations = get_fixation_frames(TRIAL) \n",
    "    \n",
    "        while success:\n",
    "            success, image = vidObj.read() \n",
    "  \n",
    "            # Saves the frames with frame-count \n",
    "            if count in fixations:\n",
    "                #print(count)\n",
    "                cv2.imwrite(os.path.join(str(TRIAL), 'frame{}.jpg'.format(count)), image)\n",
    "                TEST_IMAGE_PATHS.append(os.path.join(str(TRIAL), 'frame{}.jpg'.format(count)))\n",
    "  \n",
    "            count += 1\n",
    "    print('Count: ' + str(count))\n",
    "    print(\"Number of frames for this video: {}\".format(len(TEST_IMAGE_PATHS)))\n",
    "    \n",
    "    init_fixation_counts()\n",
    "    fixations_path = os.path.join(str(TRIAL), 'fixations.csv')\n",
    "    df = pd.read_csv(fixations_path)\n",
    "    num_rows = df.shape[0]\n",
    "    print(num_rows)\n",
    "    print(fixations[f1:f2])\n",
    "\n",
    "    for i in fixations[f1:f2]:\n",
    "      for j in range(num_rows):\n",
    "        fixation_start = df['start_frame_index'][j]\n",
    "        fixation_end = df['end_frame_index'][j]\n",
    "\n",
    "        if i in range(fixation_start, fixation_end + 1):\n",
    "          break\n",
    "\n",
    "      image_path = os.path.join(str(TRIAL), 'frame{}.jpg'.format(i))\n",
    "      image = Image.open(image_path)\n",
    "      # the array based representation of the image will be used later in order to prepare the\n",
    "      # result image with boxes and labels on it.\n",
    "      image_np = load_image_into_numpy_array(image)\n",
    "      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "      im_height, im_width, im_depth = image_np.shape\n",
    "\n",
    "      x_fixation = df['norm_pos_x'][j] * im_width\n",
    "      y_fixation = im_height * (1.0 - df['norm_pos_y'][j])\n",
    "      print(x_fixation)\n",
    "      print(y_fixation)\n",
    "      print()\n",
    "\n",
    "      # Actual detection.\n",
    "      output_dict = run_inference_for_single_image(image_np, detection_graph, x_fixation, y_fixation, j, display_type, df)\n",
    "      # Visualization of the results of a detection.\n",
    "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          output_dict['detection_boxes'],\n",
    "          output_dict['detection_classes'],\n",
    "          output_dict['detection_scores'],\n",
    "          category_index,\n",
    "          instance_masks=output_dict.get('detection_masks'),\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=8)\n",
    "      plt.figure(figsize=IMAGE_SIZE)\n",
    "      #plt.imshow(image_np)\n",
    "\n",
    "      plt.imsave(os.path.join(str(TRIAL), 'classified{}.jpg'.format(i)), image_np)\n",
    "        \n",
    "    # Takes in an array of DF indices. \n",
    "    # Returns the average length - in seconds - of fixation durations at those indices.\n",
    "\n",
    "    def find_average_fixation(arr):\n",
    "        total = 0\n",
    "\n",
    "        for i in arr:\n",
    "            length = df['end_frame_index'][i] - df['start_frame_index'][i] + 1\n",
    "            total += length\n",
    "\n",
    "        total_seconds = float(total) / 28.49\n",
    "\n",
    "        if len(arr) > 0:\n",
    "            return total_seconds / len(arr)\n",
    "\n",
    "        return 'None'\n",
    "    \n",
    "    # generate histogram of fixations on different parts of the car\n",
    "\n",
    "    names = ['Total Car Fixations', 'AV Interface Fixations', 'Windshield fixations', 'Bumper fixations']\n",
    "    fixation_counts = np.array([[display_fixations + windshield_fixations + bumper_fixations, display_fixations, windshield_fixations, bumper_fixations], \n",
    "                       [display_fixations, display_fixations, 0, 0], \n",
    "                       [windshield_fixations, 0, windshield_fixations, 0], \n",
    "                       [bumper_fixations, 0, 0, bumper_fixations]])\n",
    "\n",
    "    x_pos = [i for i, _ in enumerate(names)]\n",
    "\n",
    "    averages = []\n",
    "    #print(fixation_df_indices)\n",
    "    for key in fixation_df_indices.keys():\n",
    "        averages.append(find_average_fixation(fixation_df_indices[key]))\n",
    "\n",
    "    plt.clf()\n",
    "    fig0 = plt.bar(names, fixation_counts[0], color=['orange'])\n",
    "\n",
    "    # Clear fig0. we only needed it for the heights of the 3 fixation types.\n",
    "    plt.clf()\n",
    "\n",
    "    for i, rect in enumerate(fig0):\n",
    "        avg = averages[i]\n",
    "        if avg == 'None':\n",
    "            plt.text(rect.get_x() + rect.get_width()/2.0, rect.get_height(), 'Average fixation \\nduration: \\n\\nN / A\\n', ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "        else:\n",
    "            plt.text(rect.get_x() + rect.get_width()/2.0, rect.get_height(), 'Average fixation \\nduration: \\n\\n%.3f sec\\n' % avg, ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "    fig1 = plt.bar(names, fixation_counts[1], bottom=[0,0,0,0], color=['red'])\n",
    "    fig2 = plt.bar(names, fixation_counts[2], bottom=fixation_counts[1], color=['blue'])\n",
    "    fig3 = plt.bar(names, fixation_counts[3], bottom=fixation_counts[2] + fixation_counts[1], color=['green'])\n",
    "\n",
    "    plot_title = date[:2] + '/' + date[2:] + '\\nAV Interface Type: ' + display_type.title() + '\\nIntersection: ' + str(int(intersection))\n",
    "    #plot_title = 'Fixation Frequencies\\ngh\\ngfh'\n",
    "    plt.title(plot_title, fontsize=24)\n",
    "    plt.xlabel(\"\\nCategory of Fixation on Car\", fontsize=15)\n",
    "    plt.ylabel(\"Frequency\\n\", fontsize=15)\n",
    "    plt.xticks(x_pos, names, fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.gca().set_ylim(0, display_fixations + windshield_fixations + bumper_fixations + 2)\n",
    "    plt.subplots_adjust(top=0.7)\n",
    "\n",
    "    plt.savefig(os.path.join(str(TRIAL), 'fixations.png'))\n",
    "    \n",
    "    cols = ['id',\n",
    "     'start_timestamp',\n",
    "     'duration',\n",
    "     'start_frame_index',\n",
    "     'end_frame_index',\n",
    "     'norm_pos_x',\n",
    "     'norm_pos_y',\n",
    "     'dispersion',\n",
    "     'confidence',\n",
    "     'method',\n",
    "     'gaze_point_3d_x',\n",
    "     'gaze_point_3d_y',\n",
    "     'gaze_point_3d_z',\n",
    "     'base_data', 'fixation_type']\n",
    "\n",
    "    output_df = pd.DataFrame(output_data, columns=cols)\n",
    "    output_df.to_csv(os.path.join(str(TRIAL), 'plot_data.csv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing video...\n",
      "Count: 5859\n",
      "Number of frames for this video: 227\n",
      "227\n",
      "[3801, 3814, 3840, 3865, 3896, 3920, 3958, 3975, 4002, 4068]\n",
      "483.32146721381326\n",
      "271.7983266382454\n",
      "\n",
      "car bounding boxes:\n",
      "\n",
      "people bounding boxes:\n",
      "-----------\n",
      "20353.54389529453\n",
      "11957.819993500572\n",
      "\n",
      "car bounding boxes:\n",
      "\n",
      "people bounding boxes:\n",
      "-----------\n",
      "-50978.425940349436\n",
      "-28827.04053581023\n",
      "\n",
      "car bounding boxes:\n",
      "\n",
      "people bounding boxes:\n",
      "-----------\n",
      "-31566.49726556576\n",
      "-22515.986705305204\n",
      "\n",
      "car bounding boxes:\n",
      "Bounding boxes coords:\n",
      "527.8768157958984 581.8902587890625 355.57783126831055 391.45368576049805\n",
      "Scores: \n",
      "0.7017226\n",
      "\n",
      "Account for slant: False\n",
      "Fixation in car? False\n",
      "Display: False\n",
      "Windshield: False\n",
      "Bumper: False\n",
      "\n",
      "people bounding boxes:\n",
      "-----------\n",
      "1074.489102383593\n",
      "338.31437975524784\n",
      "\n",
      "car bounding boxes:\n",
      "\n",
      "people bounding boxes:\n",
      "-----------\n",
      "445.1639612028507\n",
      "287.29090667832884\n",
      "\n",
      "car bounding boxes:\n",
      "\n",
      "people bounding boxes:\n",
      "-----------\n",
      "502.6516791321221\n",
      "284.9101577564136\n",
      "\n",
      "car bounding boxes:\n",
      "Bounding boxes coords:\n",
      "438.1089401245117 609.0832901000977 315.43818712234497 423.02011013031006\n",
      "Scores: \n",
      "0.8559591\n",
      "\n",
      "Account for slant: False\n",
      "Fixation in car? True\n",
      "Display: True\n",
      "Windshield: False\n",
      "Bumper: False\n",
      "\n",
      "people bounding boxes:\n",
      "-----------\n",
      "423.1856718185068\n",
      "341.049875745034\n",
      "\n",
      "car bounding boxes:\n",
      "Bounding boxes coords:\n",
      "266.3116264343262 504.3055725097656 323.2636284828186 488.2374858856201\n",
      "Scores: \n",
      "0.8301134\n",
      "\n",
      "Account for slant: False\n",
      "Fixation in car? True\n",
      "Display: False\n",
      "Windshield: True\n",
      "Bumper: False\n",
      "\n",
      "people bounding boxes:\n",
      "-----------\n",
      "296.4048779386612\n",
      "355.70372680297083\n",
      "\n",
      "car bounding boxes:\n",
      "Bounding boxes coords:\n",
      "211.85691833496094 1010.6156921386719 339.28856134414673 720.0\n",
      "Scores: \n",
      "0.87773526\n",
      "\n",
      "Account for slant: True\n",
      "Fixation in car? True\n",
      "Display: True\n",
      "Windshield: False\n",
      "Bumper: False\n",
      "\n",
      "people bounding boxes:\n",
      "-----------\n",
      "775.055457406508\n",
      "354.84049256995803\n",
      "\n",
      "car bounding boxes:\n",
      "Bounding boxes coords:\n",
      "418.64013671875 595.2721405029297 264.6784543991089 371.9785737991333\n",
      "Scores: \n",
      "0.72654635\n",
      "\n",
      "Account for slant: False\n",
      "Fixation in car? False\n",
      "Display: False\n",
      "Windshield: False\n",
      "Bumper: False\n",
      "\n",
      "people bounding boxes:\n",
      "Bounding boxes coords:\n",
      "570.0649261474609 950.3643035888672 228.44414949417114 720.0\n",
      "Scores: \n",
      "0.7572352\n",
      "\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "trials = ['1108_1446_eyes_02', '1108_1457_symbols_03', '1108_1504_eyes_02',\n",
    "    '1108_1510_manual_02', '1108_1512_symbols_02', '1108_1519_eyes_03', '1108_1534_symbols_01', \n",
    "          '1108_1540_text_03', '1108_1548_text_01', '1108_1552_eyes_01', '1108_1557_text_02']\n",
    "\n",
    "f1_s = [150, 150, 120,\n",
    "    -37, -7, -37, -23,\n",
    "    -18, -8, -5, -20]\n",
    "\n",
    "f2_s = [160, 183, 142,\n",
    "    -28, -1, -30, -15,\n",
    "    -13, -4, None, -12]\n",
    "\n",
    "for i in range(-11, -10):\n",
    "    TRIAL = trials[i]\n",
    "    f1 = f1_s[i]\n",
    "    f2 = f2_s[i]\n",
    "    run_all(TRIAL, f1, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LQSEnEsPWKMj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"init_fixation_counts()\\nfixations_path = os.path.join(str(TRIAL), 'fixations.csv')\\ndf = pd.read_csv(fixations_path)\\nnum_rows = df.shape[0]\\n\\nfor i in fixations[-7:None]:\\n  for j in range(num_rows):\\n    fixation_start = df['start_frame_index'][j]\\n    fixation_end = df['end_frame_index'][j]\\n    \\n    if i in range(fixation_start, fixation_end):\\n      break\\n    \\n  image_path = os.path.join(str(TRIAL), 'frame{}.jpg'.format(i))\\n  image = Image.open(image_path)\\n  # the array based representation of the image will be used later in order to prepare the\\n  # result image with boxes and labels on it.\\n  image_np = load_image_into_numpy_array(image)\\n  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\\n  image_np_expanded = np.expand_dims(image_np, axis=0)\\n    \\n  im_height, im_width, im_depth = image_np.shape\\n\\n  x_fixation = df['norm_pos_x'][j] * im_width\\n  y_fixation = im_height * (1.0 - df['norm_pos_y'][j])\\n  print(x_fixation)\\n  print(y_fixation)\\n  print()\\n  \\n  # Actual detection.\\n  output_dict = run_inference_for_single_image(image_np, detection_graph, x_fixation, y_fixation, j, display_type)\\n  # Visualization of the results of a detection.\\n  vis_util.visualize_boxes_and_labels_on_image_array(\\n      image_np,\\n      output_dict['detection_boxes'],\\n      output_dict['detection_classes'],\\n      output_dict['detection_scores'],\\n      category_index,\\n      instance_masks=output_dict.get('detection_masks'),\\n      use_normalized_coordinates=True,\\n      line_thickness=8)\\n  plt.figure(figsize=IMAGE_SIZE)\\n  #plt.imshow(image_np)\\n  \\n  plt.imsave(os.path.join(str(TRIAL), 'classified{}.jpg'.format(i)), image_np)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''init_fixation_counts()\n",
    "fixations_path = os.path.join(str(TRIAL), 'fixations.csv')\n",
    "df = pd.read_csv(fixations_path)\n",
    "num_rows = df.shape[0]\n",
    "\n",
    "for i in fixations[-7:None]:\n",
    "  for j in range(num_rows):\n",
    "    fixation_start = df['start_frame_index'][j]\n",
    "    fixation_end = df['end_frame_index'][j]\n",
    "    \n",
    "    if i in range(fixation_start, fixation_end):\n",
    "      break\n",
    "    \n",
    "  image_path = os.path.join(str(TRIAL), 'frame{}.jpg'.format(i))\n",
    "  image = Image.open(image_path)\n",
    "  # the array based representation of the image will be used later in order to prepare the\n",
    "  # result image with boxes and labels on it.\n",
    "  image_np = load_image_into_numpy_array(image)\n",
    "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    \n",
    "  im_height, im_width, im_depth = image_np.shape\n",
    "\n",
    "  x_fixation = df['norm_pos_x'][j] * im_width\n",
    "  y_fixation = im_height * (1.0 - df['norm_pos_y'][j])\n",
    "  print(x_fixation)\n",
    "  print(y_fixation)\n",
    "  print()\n",
    "  \n",
    "  # Actual detection.\n",
    "  output_dict = run_inference_for_single_image(image_np, detection_graph, x_fixation, y_fixation, j, display_type)\n",
    "  # Visualization of the results of a detection.\n",
    "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks'),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=8)\n",
    "  plt.figure(figsize=IMAGE_SIZE)\n",
    "  #plt.imshow(image_np)\n",
    "  \n",
    "  plt.imsave(os.path.join(str(TRIAL), 'classified{}.jpg'.format(i)), image_np)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Takes in an array of DF indices. \\n# Returns the average length - in seconds - of fixation durations at those indices.\\n\\ndef find_average_fixation(arr):\\n    total = 0\\n    \\n    for i in arr:\\n        length = df['end_frame_index'][i] - df['start_frame_index'][i] + 1\\n        total += length\\n        \\n    total_seconds = float(total) / 30.0\\n    \\n    if len(arr) > 0:\\n        return total_seconds / len(arr)\\n    \\n    return 'None'\\n    \""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Takes in an array of DF indices. \n",
    "# Returns the average length - in seconds - of fixation durations at those indices.\n",
    "\n",
    "def find_average_fixation(arr):\n",
    "    total = 0\n",
    "    \n",
    "    for i in arr:\n",
    "        length = df['end_frame_index'][i] - df['start_frame_index'][i] + 1\n",
    "        total += length\n",
    "        \n",
    "    total_seconds = float(total) / 30.0\n",
    "    \n",
    "    if len(arr) > 0:\n",
    "        return total_seconds / len(arr)\n",
    "    \n",
    "    return 'None'\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# generate histogram of fixations on different parts of the car\\n\\nnames = [\\'Total Car Fixations\\', \\'AV Interface Fixations\\', \\'Windshield fixations\\', \\'Bumper fixations\\']\\nfixation_counts = np.array([[display_fixations + windshield_fixations + bumper_fixations, display_fixations, windshield_fixations, bumper_fixations], \\n                   [display_fixations, display_fixations, 0, 0], \\n                   [windshield_fixations, 0, windshield_fixations, 0], \\n                   [bumper_fixations, 0, 0, bumper_fixations]])\\n\\nx_pos = [i for i, _ in enumerate(names)]\\n\\naverages = []\\nfor key in fixation_df_indices.keys():\\n    averages.append(find_average_fixation(fixation_df_indices[key]))\\n\\nplt.clf()\\nfig0 = plt.bar(names, fixation_counts[0], color=[\\'orange\\'])\\n\\n# Clear fig0. we only needed it for the heights of the 3 fixation types.\\nplt.clf()\\n\\nfor i, rect in enumerate(fig0):\\n    avg = averages[i]\\n    if avg == \\'None\\':\\n        plt.text(rect.get_x() + rect.get_width()/2.0, rect.get_height(), \\'Average fixation \\nduration: \\n\\nN / A\\n\\', ha=\\'center\\', va=\\'bottom\\', fontsize=15)\\n        \\n    else:\\n        plt.text(rect.get_x() + rect.get_width()/2.0, rect.get_height(), \\'Average fixation \\nduration: \\n\\n%.3f sec\\n\\' % avg, ha=\\'center\\', va=\\'bottom\\', fontsize=15)\\n\\nfig1 = plt.bar(names, fixation_counts[1], bottom=[0,0,0,0], color=[\\'red\\'])\\nfig2 = plt.bar(names, fixation_counts[2], bottom=fixation_counts[1], color=[\\'blue\\'])\\nfig3 = plt.bar(names, fixation_counts[3], bottom=fixation_counts[2] + fixation_counts[1], color=[\\'green\\'])\\n\\nplot_title = date[:2] + \\'/\\' + date[2:] + \\'\\nAV Interface Type: \\' + display_type.title() + \\'\\nIntersection: \\' + str(int(intersection))\\n#plot_title = \\'Fixation Frequencies\\ngh\\ngfh\\'\\nplt.title(plot_title, fontsize=24)\\nplt.xlabel(\"\\nCategory of Fixation on Car\", fontsize=15)\\nplt.ylabel(\"Frequency\\n\", fontsize=15)\\nplt.xticks(x_pos, names, fontsize=12)\\nplt.yticks(fontsize=12)\\nplt.gca().set_ylim(0, display_fixations + windshield_fixations + bumper_fixations + 2)\\nplt.subplots_adjust(top=0.7)\\n\\nplt.savefig(os.path.join(str(TRIAL), \\'fixations.png\\'))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# generate histogram of fixations on different parts of the car\n",
    "\n",
    "names = ['Total Car Fixations', 'AV Interface Fixations', 'Windshield fixations', 'Bumper fixations']\n",
    "fixation_counts = np.array([[display_fixations + windshield_fixations + bumper_fixations, display_fixations, windshield_fixations, bumper_fixations], \n",
    "                   [display_fixations, display_fixations, 0, 0], \n",
    "                   [windshield_fixations, 0, windshield_fixations, 0], \n",
    "                   [bumper_fixations, 0, 0, bumper_fixations]])\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(names)]\n",
    "\n",
    "averages = []\n",
    "for key in fixation_df_indices.keys():\n",
    "    averages.append(find_average_fixation(fixation_df_indices[key]))\n",
    "\n",
    "plt.clf()\n",
    "fig0 = plt.bar(names, fixation_counts[0], color=['orange'])\n",
    "\n",
    "# Clear fig0. we only needed it for the heights of the 3 fixation types.\n",
    "plt.clf()\n",
    "\n",
    "for i, rect in enumerate(fig0):\n",
    "    avg = averages[i]\n",
    "    if avg == 'None':\n",
    "        plt.text(rect.get_x() + rect.get_width()/2.0, rect.get_height(), 'Average fixation \\nduration: \\n\\nN / A\\n', ha='center', va='bottom', fontsize=15)\n",
    "        \n",
    "    else:\n",
    "        plt.text(rect.get_x() + rect.get_width()/2.0, rect.get_height(), 'Average fixation \\nduration: \\n\\n%.3f sec\\n' % avg, ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "fig1 = plt.bar(names, fixation_counts[1], bottom=[0,0,0,0], color=['red'])\n",
    "fig2 = plt.bar(names, fixation_counts[2], bottom=fixation_counts[1], color=['blue'])\n",
    "fig3 = plt.bar(names, fixation_counts[3], bottom=fixation_counts[2] + fixation_counts[1], color=['green'])\n",
    "\n",
    "plot_title = date[:2] + '/' + date[2:] + '\\nAV Interface Type: ' + display_type.title() + '\\nIntersection: ' + str(int(intersection))\n",
    "#plot_title = 'Fixation Frequencies\\ngh\\ngfh'\n",
    "plt.title(plot_title, fontsize=24)\n",
    "plt.xlabel(\"\\nCategory of Fixation on Car\", fontsize=15)\n",
    "plt.ylabel(\"Frequency\\n\", fontsize=15)\n",
    "plt.xticks(x_pos, names, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.gca().set_ylim(0, display_fixations + windshield_fixations + bumper_fixations + 2)\n",
    "plt.subplots_adjust(top=0.7)\n",
    "\n",
    "plt.savefig(os.path.join(str(TRIAL), 'fixations.png'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cols = ['id',\\n 'start_timestamp',\\n 'duration',\\n 'start_frame_index',\\n 'end_frame_index',\\n 'norm_pos_x',\\n 'norm_pos_y',\\n 'dispersion',\\n 'confidence',\\n 'method',\\n 'gaze_point_3d_x',\\n 'gaze_point_3d_y',\\n 'gaze_point_3d_z',\\n 'base_data', 'fixation_type']\\n\\noutput_df = pd.DataFrame(output_data, columns=cols)\\noutput_df.to_csv(os.path.join(str(TRIAL), 'plot_data.csv'), sep='\\t')\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cols = ['id',\n",
    " 'start_timestamp',\n",
    " 'duration',\n",
    " 'start_frame_index',\n",
    " 'end_frame_index',\n",
    " 'norm_pos_x',\n",
    " 'norm_pos_y',\n",
    " 'dispersion',\n",
    " 'confidence',\n",
    " 'method',\n",
    " 'gaze_point_3d_x',\n",
    " 'gaze_point_3d_y',\n",
    " 'gaze_point_3d_z',\n",
    " 'base_data', 'fixation_type']\n",
    "\n",
    "output_df = pd.DataFrame(output_data, columns=cols)\n",
    "output_df.to_csv(os.path.join(str(TRIAL), 'plot_data.csv'), sep='\\t')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixations_by_interface(fix_type):   \n",
    "    interfaces = {}\n",
    "    bumper_fixations = 0\n",
    "    windshield_fixations = 0\n",
    "    display_fixations = 0\n",
    "    \n",
    "    fixation_lengths = [0,0,0,0]\n",
    "    num_fixations = [0,0,0,0]\n",
    "    \n",
    "    subs = [x[0] for x in os.walk(os.getcwd()) if \n",
    "            ('1108' in os.path.basename(x[0]) or '1108' in os.path.basename(x[0])) and\n",
    "               (fix_type in os.path.basename(x[0]))]\n",
    "    \n",
    "    for subdir in subs:\n",
    "        # track # of times each interface was tested\n",
    "        print(subdir)\n",
    "        \n",
    "        date, trial_num, display_type, intersection = os.path.basename(subdir).split('_')\n",
    "        if display_type in interfaces.keys():\n",
    "            interfaces[display_type] += 1\n",
    "        else:\n",
    "            interfaces[display_type] = 0\n",
    "        \n",
    "        fixations_count = 0\n",
    "        f = os.path.join(subdir, 'plot_data.csv')\n",
    "        if os.path.exists(f):\n",
    "            plot_data = pd.read_csv(f, sep='\\t')\n",
    "            for j in range(plot_data.shape[0]):\n",
    "                fixation = plot_data['fixation_type'][j]\n",
    "                length = plot_data['end_frame_index'][j] - plot_data['start_frame_index'][j] + 1\n",
    "                total = length\n",
    "                total_seconds = float(total) / 28.49\n",
    "            \n",
    "                if fixation == 'interface':\n",
    "                    num_fixations[1] += 1\n",
    "                    fixation_lengths[1] += total_seconds\n",
    "                    \n",
    "                elif fixation == 'windshield':\n",
    "                    num_fixations[2] += 1\n",
    "                    fixation_lengths[2] += total_seconds\n",
    "                    \n",
    "                elif fixation == 'bumper':\n",
    "                    num_fixations[3] += 1\n",
    "                    fixation_lengths[3] += total_seconds\n",
    "                    \n",
    "    fixation_lengths[0] = sum(fixation_lengths)\n",
    "    num_fixations[0] = sum(num_fixations)\n",
    "                    \n",
    "    names = ['Total Car Fixations', 'AV Interface Fixations', 'Windshield fixations', 'Bumper fixations']\n",
    "    fixation_counts = np.array([[num_fixations[0], num_fixations[1], num_fixations[2], num_fixations[3]], \n",
    "                       [num_fixations[1], num_fixations[1], 0, 0], \n",
    "                       [num_fixations[2], 0, num_fixations[2], 0], \n",
    "                       [num_fixations[3], 0, 0, num_fixations[3]]]) / float(len(subs))\n",
    "\n",
    "    x_pos = [i for i, _ in enumerate(names)]\n",
    "\n",
    "    plt.clf()\n",
    "    fig0 = plt.bar(names, fixation_counts[0], color=['orange'])\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    # Clear fig0. we only needed it for the heights of the 3 fixation types.\n",
    "    plt.clf()\n",
    "\n",
    "    for i, rect in enumerate(fig0):\n",
    "        if num_fixations[i] == 0:\n",
    "            plt.text(rect.get_x() + rect.get_width()/2.0, rect.get_height(), 'Average fixation \\nduration across \\nall subjects, all trials: \\n\\nN / A\\n', ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "        else:\n",
    "            plt.text(rect.get_x() + rect.get_width()/2.0, rect.get_height(), 'Average fixation \\nduration across \\nall subjects, all trials: \\n\\n%.3f sec\\n' % (float(fixation_lengths[i]) / num_fixations[i]), ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "    fig1 = plt.bar(names, fixation_counts[1], bottom=[0,0,0,0], color=['red'])\n",
    "    fig2 = plt.bar(names, fixation_counts[2], bottom=fixation_counts[1], color=['blue'])\n",
    "    fig3 = plt.bar(names, fixation_counts[3], bottom=fixation_counts[2] + fixation_counts[1], color=['green'])\n",
    "\n",
    "    plot_title = 'Interface Type: ' + fix_type.title() + '\\n'\n",
    "    if fix_type == 'nodisplay':\n",
    "        plot_title = 'Interface Type: ' + 'No Display ' + '\\n'\n",
    "    \n",
    "    plt.title(plot_title, fontsize=24)\n",
    "    plt.xlabel(\"\\nCategory of Fixation on Car\", fontsize=15)\n",
    "    plt.ylabel(\"Frequency\\n\", fontsize=15)\n",
    "    plt.xticks(x_pos, names, fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.gca().set_ylim(0, 7)\n",
    "    plt.subplots_adjust(top=0.7)\n",
    "\n",
    "    plt.savefig(fix_type + 'fixations.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1540_text_03\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1548_text_01\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1557_text_02\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1457_symbols_03\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1534_symbols_01\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1512_symbols_02\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1504_eyes_02\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1446_eyes_02\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1552_eyes_01\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1519_eyes_03\n",
      "/Users/shaantam/Documents/BDD/tensorflow/models/research/object_detection/1108_1510_manual_02\n"
     ]
    }
   ],
   "source": [
    "#types = ['text', 'symbol', 'eyes', 'nodisplay', 'manual']\n",
    "types = ['text', 'symbol', 'eyes', 'manual']\n",
    "for t in types:\n",
    "    fixations_by_interface(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
